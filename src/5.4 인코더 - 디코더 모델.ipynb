{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63a33736-f02c-47cb-bbf0-0f60c10edadb",
   "metadata": {},
   "source": [
    "# 5.4.2 Conditional Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dab824-6a3b-4e44-9e93-51fc44bbb16a",
   "metadata": {},
   "source": [
    "## 5.4.2.1 모델 구조 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "030280e5-86cc-4e9a-b977-f268b181682c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "/home/nsw/.pyenv/versions/3.9.16/envs/base/lib/python3.9/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(30000, 768, padding_idx=3)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=30000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('hyunwoongko/kobart')\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('hyunwoongko/kobart')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004a7c77-0866-4b13-b462-c9dd1813272d",
   "metadata": {},
   "source": [
    "## 5.4.2.2 데이터셋 구조 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44858dcb-3b4c-4a10-b781-c2a4b12de839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['korean', 'english'],\n",
      "        num_rows: 166215\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['korean', 'english'],\n",
      "        num_rows: 1958\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['korean', 'english'],\n",
      "        num_rows: 1982\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'korean': '(박수) 이쪽은 Bill Lange 이고, 저는 David Gallo입니다',\n",
       " 'english': \"(Applause) David Gallo: This is Bill Lange. I'm Dave Gallo.\"}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"msarmi9/korean-english-multitarget-ted-talks-task\")\n",
    "print(dataset)\n",
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68f49c5b-3e18-4d2a-bb1b-65b23e8b9d50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2fabff2ff7745919b05b42854a277f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/166215 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nsw/.pyenv/versions/3.9.16/envs/base/lib/python3.9/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5297faa962544f79959b9454bfc2d9e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/1958 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3374934a084572ae6905ffb2e941a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/1982 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0,\n",
       "  14338,\n",
       "  10770,\n",
       "  11372,\n",
       "  240,\n",
       "  14025,\n",
       "  12471,\n",
       "  12005,\n",
       "  15085,\n",
       "  29490,\n",
       "  14676,\n",
       "  24508,\n",
       "  300,\n",
       "  14025,\n",
       "  14161,\n",
       "  16530,\n",
       "  15529,\n",
       "  296,\n",
       "  317,\n",
       "  18509,\n",
       "  15464,\n",
       "  15585,\n",
       "  20858,\n",
       "  12049,\n",
       "  20211,\n",
       "  1],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'labels': [0,\n",
       "  14338,\n",
       "  264,\n",
       "  311,\n",
       "  311,\n",
       "  17422,\n",
       "  316,\n",
       "  17223,\n",
       "  240,\n",
       "  15529,\n",
       "  296,\n",
       "  317,\n",
       "  18509,\n",
       "  15464,\n",
       "  15585,\n",
       "  20858,\n",
       "  257,\n",
       "  15054,\n",
       "  303,\n",
       "  15868,\n",
       "  1700,\n",
       "  15868,\n",
       "  15085,\n",
       "  29490,\n",
       "  14676,\n",
       "  24508,\n",
       "  300,\n",
       "  245,\n",
       "  14943,\n",
       "  238,\n",
       "  308,\n",
       "  15529,\n",
       "  296,\n",
       "  21518,\n",
       "  15464,\n",
       "  15585,\n",
       "  20858,\n",
       "  245,\n",
       "  1]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(\n",
    "    lambda batch: (\n",
    "        tokenizer(\n",
    "            batch[\"korean\"], \n",
    "            text_target=batch[\"english\"], \n",
    "            max_length=512, \n",
    "            truncation=True,\n",
    "        )\n",
    "    ),\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=2,\n",
    "    remove_columns=dataset['train'].column_names,\n",
    ")\n",
    "tokenized_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0b1461f-c5b3-489b-bebe-e9643c19380c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0, 14338, 10770,  ...,     3,     3,     3],\n",
       "        [    0, 15496, 18918,  ...,     3,     3,     3]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[    0, 14338,   264,   311,   311, 17422,   316, 17223,   240, 15529,\n",
       "           296,   317, 18509, 15464, 15585, 20858,   257, 15054,   303, 15868,\n",
       "          1700, 15868, 15085, 29490, 14676, 24508,   300,   245, 14943,   238,\n",
       "           308, 15529,   296, 21518, 15464, 15585, 20858,   245,     1,  -100,\n",
       "          -100],\n",
       "        [    0, 14603,   309,   299, 20676,   300,   238, 16651, 25505,   310,\n",
       "         17163, 27141, 18090, 26592, 27842, 17884, 18482, 17762,   300,  1700,\n",
       "         17510, 15463,   304, 15972, 17254,   313, 17762, 21235,  1700, 17223,\n",
       "           296, 21582, 14879,   300, 22692, 20290, 18509,   300,   310,   245,\n",
       "             1]]), 'decoder_input_ids': tensor([[    1,     0, 14338,   264,   311,   311, 17422,   316, 17223,   240,\n",
       "         15529,   296,   317, 18509, 15464, 15585, 20858,   257, 15054,   303,\n",
       "         15868,  1700, 15868, 15085, 29490, 14676, 24508,   300,   245, 14943,\n",
       "           238,   308, 15529,   296, 21518, 15464, 15585, 20858,   245,     1,\n",
       "             3],\n",
       "        [    1,     0, 14603,   309,   299, 20676,   300,   238, 16651, 25505,\n",
       "           310, 17163, 27141, 18090, 26592, 27842, 17884, 18482, 17762,   300,\n",
       "          1700, 17510, 15463,   304, 15972, 17254,   313, 17762, 21235,  1700,\n",
       "         17223,   296, 21582, 14879,   300, 22692, 20290, 18509,   300,   310,\n",
       "           245]])}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer, \n",
    "    model=model,\n",
    "    padding=\"max_length\", \n",
    "    max_length=512,\n",
    ")\n",
    "batch = collator([tokenized_dataset['train'][i] for i in range(2)])\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "00dea6a4-e38f-428f-9219-bd330760ba33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  5.4885,  18.7849,  -0.5489,  ...,   0.0465,   0.5813,  -2.2851],\n",
       "         [  3.7287,  18.9676,  -1.1747,  ...,  -0.2600,  -3.4647,  -0.0973],\n",
       "         [ -1.2976,   8.6322,  -5.0410,  ...,  -7.0689,  -6.1346,  -4.4141],\n",
       "         ...,\n",
       "         [ -2.7561,  16.9120,  -6.2025,  ...,  -8.5129,  -7.0815,  -3.8487],\n",
       "         [ -2.1361,   5.4728,  -5.2418,  ...,  -7.7049,  -7.2046,   0.2345],\n",
       "         [ -0.4232,  14.1137,  -2.5153,  ...,  -5.5002,  -4.2847,  -3.9247]],\n",
       "\n",
       "        [[  4.7748,  16.2666,  -3.0011,  ...,  -0.8965,  -3.3187,  -3.1041],\n",
       "         [  0.6535,  19.3665,  -1.4506,  ...,   0.1562,  -4.3976,   0.1983],\n",
       "         [ -5.0934,  10.8673,  -7.5637,  ...,  -6.3808,  -1.6471,  -7.2105],\n",
       "         ...,\n",
       "         [ -2.8657,  17.2623,  -6.0920,  ...,  -7.6660,  -8.1921,  -6.4258],\n",
       "         [ -4.9753,  17.3067,  -5.8232,  ...,  -6.3836,  -7.4397,  -4.2650],\n",
       "         [ -4.1442,  19.1999,  -4.2810,  ...,  -5.7311, -10.2604,  -2.9040]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**batch).logits\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bd81c466-f2d5-441d-880c-c223251dc0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import GenerationConfig\n",
    "\n",
    "gen_cfg = GenerationConfig(\n",
    "    max_new_tokens=100,\n",
    "    do_sample=True,\n",
    "    temperature=1.2,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    ")\n",
    "outputs = model.generate(batch['input_ids'], generation_config=gen_cfg)\n",
    "result = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52b8f167-79e5-4282-ba2d-ee897f578462",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.eos_token_id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
